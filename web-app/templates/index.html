<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gesture Recognition App</title>
    <link
      rel="stylesheet"
      href="{{ url_for('static', filename='style.css') }}"
    />
  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar">
      <div class="container">
        <div class="nav-brand">Beluga</div>
        <ul class="nav-links">
          <li><a href="#home">Home</a></li>
          <li><a href="#camera">Camera</a></li>
          <li><a href="#features">Features</a></li>
          <li><a href="#about">About</a></li>
        </ul>
      </div>
    </nav>

    <!-- Hero Section -->
    <section id="home" class="hero">
      <div class="container">
        <div class="hero-content">
          <h1 class="hero-title">AI-Powered Gesture Recognition</h1>
          <p class="hero-subtitle">
            Detect and classify hand gestures in real-time using advanced
            machine learning technology
          </p>
          <div class="hero-buttons">
            <a href="#features" class="btn btn-primary">Learn More</a>
          </div>
        </div>
      </div>
    </section>

    <!-- Camera Section -->
    <section id="camera" class="camera-section">
      <div class="container">
        <h2 class="section-title">Capture Gesture</h2>
        <p class="section-subtitle">
          Use your camera to capture hand gestures for recognition
        </p>
        <div class="camera-container">
          <div class="camera-wrapper">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas" style="display: none;"></canvas>
            <div class="camera-controls">
              <button id="startCamera" class="btn btn-primary">
                Start Camera
              </button>
              <button id="capturePhoto" class="btn btn-primary" style="display: none;">
                Capture Photo
              </button>
              <button id="stopCamera" class="btn btn-secondary" style="display: none;">
                Stop Camera
              </button>
            </div>
            <div id="capturedImage" class="captured-image" style="display: none;">
              <h3>Captured Image:</h3>
              <img id="preview" alt="Captured image" />
              <div class="upload-controls">
                <button id="sendToML" class="btn btn-primary">Send for Analysis</button>
                <button id="discard" class="btn btn-secondary">Discard</button>
              </div>
              <div id="result" class="analysis-result" style="display: none;"></div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Features Section -->
    <section id="features" class="features">
      <div class="container">
        <h2 class="section-title">Supported Gestures</h2>
        <p class="section-subtitle">
          Our ML model can recognize the following hand gestures
        </p>
        <div class="features-grid">
          <div class="feature-card">
            <div class="feature-icon">üëç</div>
            <h3 class="feature-title">Thumbs Up</h3>
            <p class="feature-description">
              Positive gesture recognition for approval signals
            </p>
          </div>
          <div class="feature-card">
            <div class="feature-icon">üëé</div>
            <h3 class="feature-title">Thumbs Down</h3>
            <p class="feature-description">
              Negative gesture recognition for disapproval signals
            </p>
          </div>
          <div class="feature-card">
            <div class="feature-icon">‚úã</div>
            <h3 class="feature-title">Open Palm</h3>
            <p class="feature-description">
              Stop or halt gesture detection with high accuracy
            </p>
          </div>
          <div class="feature-card">
            <div class="feature-icon">‚úä</div>
            <h3 class="feature-title">Fist</h3>
            <p class="feature-description">
              Closed fist gesture recognition for various commands
            </p>
          </div>
          <div class="feature-card">
            <div class="feature-icon">‚úåÔ∏è</div>
            <h3 class="feature-title">Victory</h3>
            <p class="feature-description">
              Peace or victory sign detection with precise recognition
            </p>
          </div>
          <div class="feature-card">
            <div class="feature-icon">üöÄ</div>
            <h3 class="feature-title">Real-time Analysis</h3>
            <p class="feature-description">
              Fast, local processing powered by MediaPipe technology
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- About Section -->
    <section id="about" class="about">
      <div class="container">
        <div class="about-content">
          <div class="about-text">
            <h2 class="section-title">How It Works</h2>
            <p class="about-description">
              Our gesture recognition system uses Google MediaPipe Hands, a
              state-of-the-art machine learning model that processes hand
              landmarks in real-time. The system analyzes 21 hand landmarks to
              accurately classify gestures with high precision.
            </p>
            <p class="about-description">
              All recognition results are stored in MongoDB, providing you with
              a complete overview of gesture detection activity and analytics.
            </p>
            <ul class="about-features">
              <li>‚úÖ Containerized architecture for easy deployment</li>
              <li>‚úÖ Real-time gesture detection and classification</li>
              <li>‚úÖ Persistent data storage with MongoDB</li>
              <li>‚úÖ Web-based interface for visualization</li>
            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
      <div class="container">
        <p>Beluga</p>
      </div>
    </footer>

    <script>
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const startCameraBtn = document.getElementById("startCamera");
      const capturePhotoBtn = document.getElementById("capturePhoto");
      const stopCameraBtn = document.getElementById("stopCamera");
      const capturedImageDiv = document.getElementById("capturedImage");
      const preview = document.getElementById("preview");
      const sendToMLBtn = document.getElementById("sendToML");
      const discardBtn = document.getElementById("discard");
      const resultDiv = document.getElementById("result");
      let stream = null;

      // Start camera
      startCameraBtn.addEventListener("click", async () => {
        try {
          stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: "user" },
          });
          video.srcObject = stream;
          startCameraBtn.style.display = "none";
          capturePhotoBtn.style.display = "inline-block";
          stopCameraBtn.style.display = "inline-block";
        } catch (err) {
          console.error("Error accessing camera:", err);
          alert("Could not access camera. Please ensure permissions are granted.");
        }
      });

      // Stop camera
      stopCameraBtn.addEventListener("click", () => {
        if (stream) {
          stream.getTracks().forEach((track) => track.stop());
          stream = null;
        }
        video.srcObject = null;
        startCameraBtn.style.display = "inline-block";
        capturePhotoBtn.style.display = "none";
        stopCameraBtn.style.display = "none";
        capturedImageDiv.style.display = "none";
      });

      // Capture photo
      capturePhotoBtn.addEventListener("click", () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const ctx = canvas.getContext("2d");
        ctx.drawImage(video, 0, 0);
        const imageData = canvas.toDataURL("image/jpeg");
        preview.src = imageData;
        capturedImageDiv.style.display = "block";
        resultDiv.style.display = "none";
      });

      // Discard captured image
      discardBtn.addEventListener("click", () => {
        capturedImageDiv.style.display = "none";
        resultDiv.style.display = "none";
      });

      // Send to ML client
      sendToMLBtn.addEventListener("click", async () => {
        const imageData = canvas.toDataURL("image/jpeg");
        sendToMLBtn.disabled = true;
        sendToMLBtn.textContent = "Processing...";

        try {
          const response = await fetch("/analyze", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ image: imageData }),
          });

          const result = await response.json();
          
          if (response.ok) {
            resultDiv.style.display = "block";
            let resultHTML = `
              <h4>Analysis Result:</h4>
              <p><strong>Label:</strong> ${result.label}</p>
              <p><strong>Confidence:</strong> ${(result.confidence * 100).toFixed(2)}%</p>
              <p><strong>Emoji:</strong> ${result.emoji || "N/A"}</p>
            `;
            if (result.message) {
              resultHTML += `<p class="info-message"><em>${result.message}</em></p>`;
            }
            resultDiv.innerHTML = resultHTML;
          } else {
            throw new Error(result.error || "Analysis failed");
          }
        } catch (error) {
          console.error("Error sending image:", error);
          alert("Error analyzing image: " + error.message);
        } finally {
          sendToMLBtn.disabled = false;
          sendToMLBtn.textContent = "Send for Analysis";
        }
      });
    </script>
  </body>
</html>
